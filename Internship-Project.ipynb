{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hill Valley Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/YBIFoundation/Dataset/blob/main/Hill%20Valley%20Dataset.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V92</th>\n",
       "      <th>V93</th>\n",
       "      <th>V94</th>\n",
       "      <th>V95</th>\n",
       "      <th>V96</th>\n",
       "      <th>V97</th>\n",
       "      <th>V98</th>\n",
       "      <th>V99</th>\n",
       "      <th>V100</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.02</td>\n",
       "      <td>36.49</td>\n",
       "      <td>38.20</td>\n",
       "      <td>38.85</td>\n",
       "      <td>39.38</td>\n",
       "      <td>39.74</td>\n",
       "      <td>37.02</td>\n",
       "      <td>39.53</td>\n",
       "      <td>38.81</td>\n",
       "      <td>38.79</td>\n",
       "      <td>...</td>\n",
       "      <td>36.62</td>\n",
       "      <td>36.92</td>\n",
       "      <td>38.80</td>\n",
       "      <td>38.52</td>\n",
       "      <td>38.07</td>\n",
       "      <td>36.73</td>\n",
       "      <td>39.46</td>\n",
       "      <td>37.50</td>\n",
       "      <td>39.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.83</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.78</td>\n",
       "      <td>...</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68177.69</td>\n",
       "      <td>66138.42</td>\n",
       "      <td>72981.88</td>\n",
       "      <td>74304.33</td>\n",
       "      <td>67549.66</td>\n",
       "      <td>69367.34</td>\n",
       "      <td>69169.41</td>\n",
       "      <td>73268.61</td>\n",
       "      <td>74465.84</td>\n",
       "      <td>72503.37</td>\n",
       "      <td>...</td>\n",
       "      <td>73438.88</td>\n",
       "      <td>71053.35</td>\n",
       "      <td>71112.62</td>\n",
       "      <td>74916.48</td>\n",
       "      <td>72571.58</td>\n",
       "      <td>66348.97</td>\n",
       "      <td>71063.72</td>\n",
       "      <td>67404.27</td>\n",
       "      <td>74920.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44889.06</td>\n",
       "      <td>39191.86</td>\n",
       "      <td>40728.46</td>\n",
       "      <td>38576.36</td>\n",
       "      <td>45876.06</td>\n",
       "      <td>47034.00</td>\n",
       "      <td>46611.43</td>\n",
       "      <td>37668.32</td>\n",
       "      <td>40980.89</td>\n",
       "      <td>38466.15</td>\n",
       "      <td>...</td>\n",
       "      <td>42625.67</td>\n",
       "      <td>40684.20</td>\n",
       "      <td>46960.73</td>\n",
       "      <td>44546.80</td>\n",
       "      <td>45410.53</td>\n",
       "      <td>47139.44</td>\n",
       "      <td>43095.68</td>\n",
       "      <td>40888.34</td>\n",
       "      <td>39615.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.70</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.28</td>\n",
       "      <td>5.38</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.61</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.38</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.87</td>\n",
       "      <td>...</td>\n",
       "      <td>5.17</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.94</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.22</td>\n",
       "      <td>5.30</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     39.02     36.49     38.20     38.85     39.38     39.74     37.02   \n",
       "1      1.83      1.71      1.77      1.77      1.68      1.78      1.80   \n",
       "2  68177.69  66138.42  72981.88  74304.33  67549.66  69367.34  69169.41   \n",
       "3  44889.06  39191.86  40728.46  38576.36  45876.06  47034.00  46611.43   \n",
       "4      5.70      5.40      5.28      5.38      5.27      5.61      6.00   \n",
       "\n",
       "         V8        V9       V10  ...       V92       V93       V94       V95  \\\n",
       "0     39.53     38.81     38.79  ...     36.62     36.92     38.80     38.52   \n",
       "1      1.70      1.75      1.78  ...      1.80      1.79      1.77      1.74   \n",
       "2  73268.61  74465.84  72503.37  ...  73438.88  71053.35  71112.62  74916.48   \n",
       "3  37668.32  40980.89  38466.15  ...  42625.67  40684.20  46960.73  44546.80   \n",
       "4      5.38      5.34      5.87  ...      5.17      5.67      5.60      5.94   \n",
       "\n",
       "        V96       V97       V98       V99      V100  Class  \n",
       "0     38.07     36.73     39.46     37.50     39.10      0  \n",
       "1      1.74      1.80      1.78      1.75      1.69      1  \n",
       "2  72571.58  66348.97  71063.72  67404.27  74920.24      1  \n",
       "3  45410.53  47139.44  43095.68  40888.34  39615.19      0  \n",
       "4      5.73      5.22      5.30      5.73      5.91      0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"https://github.com/YBIFoundation/Dataset/blob/main/Hill%20Valley%20Dataset.csv\")\n",
    "# I am using downloaded version of data source from github.\n",
    "df = pd.read_csv(\"Hill Valley Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V92</th>\n",
       "      <th>V93</th>\n",
       "      <th>V94</th>\n",
       "      <th>V95</th>\n",
       "      <th>V96</th>\n",
       "      <th>V97</th>\n",
       "      <th>V98</th>\n",
       "      <th>V99</th>\n",
       "      <th>V100</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8169.091881</td>\n",
       "      <td>8144.306262</td>\n",
       "      <td>8192.653738</td>\n",
       "      <td>8176.868738</td>\n",
       "      <td>8128.297211</td>\n",
       "      <td>8173.030008</td>\n",
       "      <td>8188.582748</td>\n",
       "      <td>8183.641543</td>\n",
       "      <td>8154.670066</td>\n",
       "      <td>8120.767574</td>\n",
       "      <td>...</td>\n",
       "      <td>8120.056815</td>\n",
       "      <td>8125.917409</td>\n",
       "      <td>8158.793812</td>\n",
       "      <td>8140.885421</td>\n",
       "      <td>8213.480611</td>\n",
       "      <td>8185.594002</td>\n",
       "      <td>8140.195355</td>\n",
       "      <td>8192.960891</td>\n",
       "      <td>8156.197376</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17974.950461</td>\n",
       "      <td>17881.049734</td>\n",
       "      <td>18087.938901</td>\n",
       "      <td>17991.903982</td>\n",
       "      <td>17846.757963</td>\n",
       "      <td>17927.114105</td>\n",
       "      <td>18029.562695</td>\n",
       "      <td>18048.582159</td>\n",
       "      <td>17982.390713</td>\n",
       "      <td>17900.798206</td>\n",
       "      <td>...</td>\n",
       "      <td>17773.190621</td>\n",
       "      <td>17758.182403</td>\n",
       "      <td>17919.510371</td>\n",
       "      <td>17817.945646</td>\n",
       "      <td>18016.445265</td>\n",
       "      <td>17956.084223</td>\n",
       "      <td>17768.356106</td>\n",
       "      <td>18064.781479</td>\n",
       "      <td>17829.310973</td>\n",
       "      <td>0.500206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.602500</td>\n",
       "      <td>19.595000</td>\n",
       "      <td>18.925000</td>\n",
       "      <td>19.277500</td>\n",
       "      <td>19.210000</td>\n",
       "      <td>19.582500</td>\n",
       "      <td>18.690000</td>\n",
       "      <td>19.062500</td>\n",
       "      <td>19.532500</td>\n",
       "      <td>19.285000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.197500</td>\n",
       "      <td>18.895000</td>\n",
       "      <td>19.237500</td>\n",
       "      <td>19.385000</td>\n",
       "      <td>19.027500</td>\n",
       "      <td>19.135000</td>\n",
       "      <td>19.205000</td>\n",
       "      <td>18.812500</td>\n",
       "      <td>19.145000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>301.425000</td>\n",
       "      <td>295.205000</td>\n",
       "      <td>297.260000</td>\n",
       "      <td>299.720000</td>\n",
       "      <td>295.115000</td>\n",
       "      <td>294.380000</td>\n",
       "      <td>295.935000</td>\n",
       "      <td>290.850000</td>\n",
       "      <td>294.565000</td>\n",
       "      <td>295.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>297.845000</td>\n",
       "      <td>295.420000</td>\n",
       "      <td>299.155000</td>\n",
       "      <td>293.355000</td>\n",
       "      <td>301.370000</td>\n",
       "      <td>296.960000</td>\n",
       "      <td>300.925000</td>\n",
       "      <td>299.200000</td>\n",
       "      <td>302.275000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5358.795000</td>\n",
       "      <td>5417.847500</td>\n",
       "      <td>5393.367500</td>\n",
       "      <td>5388.482500</td>\n",
       "      <td>5321.987500</td>\n",
       "      <td>5328.040000</td>\n",
       "      <td>5443.977500</td>\n",
       "      <td>5283.655000</td>\n",
       "      <td>5378.180000</td>\n",
       "      <td>5319.097500</td>\n",
       "      <td>...</td>\n",
       "      <td>5355.355000</td>\n",
       "      <td>5386.037500</td>\n",
       "      <td>5286.385000</td>\n",
       "      <td>5345.797500</td>\n",
       "      <td>5300.890000</td>\n",
       "      <td>5361.047500</td>\n",
       "      <td>5390.850000</td>\n",
       "      <td>5288.712500</td>\n",
       "      <td>5357.847500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>117807.870000</td>\n",
       "      <td>108896.480000</td>\n",
       "      <td>119031.350000</td>\n",
       "      <td>110212.590000</td>\n",
       "      <td>113000.470000</td>\n",
       "      <td>116848.390000</td>\n",
       "      <td>115609.240000</td>\n",
       "      <td>118522.320000</td>\n",
       "      <td>112895.900000</td>\n",
       "      <td>117798.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>113858.680000</td>\n",
       "      <td>112948.830000</td>\n",
       "      <td>112409.570000</td>\n",
       "      <td>112933.730000</td>\n",
       "      <td>112037.220000</td>\n",
       "      <td>115110.420000</td>\n",
       "      <td>116431.960000</td>\n",
       "      <td>113291.960000</td>\n",
       "      <td>114533.760000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  V1             V2             V3             V4  \\\n",
       "count    1212.000000    1212.000000    1212.000000    1212.000000   \n",
       "mean     8169.091881    8144.306262    8192.653738    8176.868738   \n",
       "std     17974.950461   17881.049734   18087.938901   17991.903982   \n",
       "min         0.920000       0.900000       0.850000       0.890000   \n",
       "25%        19.602500      19.595000      18.925000      19.277500   \n",
       "50%       301.425000     295.205000     297.260000     299.720000   \n",
       "75%      5358.795000    5417.847500    5393.367500    5388.482500   \n",
       "max    117807.870000  108896.480000  119031.350000  110212.590000   \n",
       "\n",
       "                  V5             V6             V7             V8  \\\n",
       "count    1212.000000    1212.000000    1212.000000    1212.000000   \n",
       "mean     8128.297211    8173.030008    8188.582748    8183.641543   \n",
       "std     17846.757963   17927.114105   18029.562695   18048.582159   \n",
       "min         0.880000       0.860000       0.870000       0.650000   \n",
       "25%        19.210000      19.582500      18.690000      19.062500   \n",
       "50%       295.115000     294.380000     295.935000     290.850000   \n",
       "75%      5321.987500    5328.040000    5443.977500    5283.655000   \n",
       "max    113000.470000  116848.390000  115609.240000  118522.320000   \n",
       "\n",
       "                  V9            V10  ...            V92            V93  \\\n",
       "count    1212.000000    1212.000000  ...    1212.000000    1212.000000   \n",
       "mean     8154.670066    8120.767574  ...    8120.056815    8125.917409   \n",
       "std     17982.390713   17900.798206  ...   17773.190621   17758.182403   \n",
       "min         0.650000       0.620000  ...       0.870000       0.900000   \n",
       "25%        19.532500      19.285000  ...      19.197500      18.895000   \n",
       "50%       294.565000     295.160000  ...     297.845000     295.420000   \n",
       "75%      5378.180000    5319.097500  ...    5355.355000    5386.037500   \n",
       "max    112895.900000  117798.300000  ...  113858.680000  112948.830000   \n",
       "\n",
       "                 V94            V95            V96            V97  \\\n",
       "count    1212.000000    1212.000000    1212.000000    1212.000000   \n",
       "mean     8158.793812    8140.885421    8213.480611    8185.594002   \n",
       "std     17919.510371   17817.945646   18016.445265   17956.084223   \n",
       "min         0.870000       0.880000       0.890000       0.890000   \n",
       "25%        19.237500      19.385000      19.027500      19.135000   \n",
       "50%       299.155000     293.355000     301.370000     296.960000   \n",
       "75%      5286.385000    5345.797500    5300.890000    5361.047500   \n",
       "max    112409.570000  112933.730000  112037.220000  115110.420000   \n",
       "\n",
       "                 V98            V99           V100        Class  \n",
       "count    1212.000000    1212.000000    1212.000000  1212.000000  \n",
       "mean     8140.195355    8192.960891    8156.197376     0.500000  \n",
       "std     17768.356106   18064.781479   17829.310973     0.500206  \n",
       "min         0.860000       0.910000       0.890000     0.000000  \n",
       "25%        19.205000      18.812500      19.145000     0.000000  \n",
       "50%       300.925000     299.200000     302.275000     0.500000  \n",
       "75%      5390.850000    5288.712500    5357.847500     1.000000  \n",
       "max    116431.960000  113291.960000  114533.760000     1.000000  \n",
       "\n",
       "[8 rows x 101 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1212 entries, 0 to 1211\n",
      "Columns: 101 entries, V1 to Class\n",
      "dtypes: float64(100), int64(1)\n",
      "memory usage: 956.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       ...\n",
       "       'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100',\n",
       "       'Class'],\n",
       "      dtype='object', length=101)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Target Variable (y) and Feature Variables (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Class\",axis=1)\n",
    "y = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V91</th>\n",
       "      <th>V92</th>\n",
       "      <th>V93</th>\n",
       "      <th>V94</th>\n",
       "      <th>V95</th>\n",
       "      <th>V96</th>\n",
       "      <th>V97</th>\n",
       "      <th>V98</th>\n",
       "      <th>V99</th>\n",
       "      <th>V100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.02</td>\n",
       "      <td>36.49</td>\n",
       "      <td>38.20</td>\n",
       "      <td>38.85</td>\n",
       "      <td>39.38</td>\n",
       "      <td>39.74</td>\n",
       "      <td>37.02</td>\n",
       "      <td>39.53</td>\n",
       "      <td>38.81</td>\n",
       "      <td>38.79</td>\n",
       "      <td>...</td>\n",
       "      <td>37.57</td>\n",
       "      <td>36.62</td>\n",
       "      <td>36.92</td>\n",
       "      <td>38.80</td>\n",
       "      <td>38.52</td>\n",
       "      <td>38.07</td>\n",
       "      <td>36.73</td>\n",
       "      <td>39.46</td>\n",
       "      <td>37.50</td>\n",
       "      <td>39.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.83</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.78</td>\n",
       "      <td>...</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68177.69</td>\n",
       "      <td>66138.42</td>\n",
       "      <td>72981.88</td>\n",
       "      <td>74304.33</td>\n",
       "      <td>67549.66</td>\n",
       "      <td>69367.34</td>\n",
       "      <td>69169.41</td>\n",
       "      <td>73268.61</td>\n",
       "      <td>74465.84</td>\n",
       "      <td>72503.37</td>\n",
       "      <td>...</td>\n",
       "      <td>69384.71</td>\n",
       "      <td>73438.88</td>\n",
       "      <td>71053.35</td>\n",
       "      <td>71112.62</td>\n",
       "      <td>74916.48</td>\n",
       "      <td>72571.58</td>\n",
       "      <td>66348.97</td>\n",
       "      <td>71063.72</td>\n",
       "      <td>67404.27</td>\n",
       "      <td>74920.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44889.06</td>\n",
       "      <td>39191.86</td>\n",
       "      <td>40728.46</td>\n",
       "      <td>38576.36</td>\n",
       "      <td>45876.06</td>\n",
       "      <td>47034.00</td>\n",
       "      <td>46611.43</td>\n",
       "      <td>37668.32</td>\n",
       "      <td>40980.89</td>\n",
       "      <td>38466.15</td>\n",
       "      <td>...</td>\n",
       "      <td>47653.60</td>\n",
       "      <td>42625.67</td>\n",
       "      <td>40684.20</td>\n",
       "      <td>46960.73</td>\n",
       "      <td>44546.80</td>\n",
       "      <td>45410.53</td>\n",
       "      <td>47139.44</td>\n",
       "      <td>43095.68</td>\n",
       "      <td>40888.34</td>\n",
       "      <td>39615.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.70</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.28</td>\n",
       "      <td>5.38</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.61</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.38</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.87</td>\n",
       "      <td>...</td>\n",
       "      <td>5.52</td>\n",
       "      <td>5.17</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.94</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.22</td>\n",
       "      <td>5.30</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     39.02     36.49     38.20     38.85     39.38     39.74     37.02   \n",
       "1      1.83      1.71      1.77      1.77      1.68      1.78      1.80   \n",
       "2  68177.69  66138.42  72981.88  74304.33  67549.66  69367.34  69169.41   \n",
       "3  44889.06  39191.86  40728.46  38576.36  45876.06  47034.00  46611.43   \n",
       "4      5.70      5.40      5.28      5.38      5.27      5.61      6.00   \n",
       "\n",
       "         V8        V9       V10  ...       V91       V92       V93       V94  \\\n",
       "0     39.53     38.81     38.79  ...     37.57     36.62     36.92     38.80   \n",
       "1      1.70      1.75      1.78  ...      1.71      1.80      1.79      1.77   \n",
       "2  73268.61  74465.84  72503.37  ...  69384.71  73438.88  71053.35  71112.62   \n",
       "3  37668.32  40980.89  38466.15  ...  47653.60  42625.67  40684.20  46960.73   \n",
       "4      5.38      5.34      5.87  ...      5.52      5.17      5.67      5.60   \n",
       "\n",
       "        V95       V96       V97       V98       V99      V100  \n",
       "0     38.52     38.07     36.73     39.46     37.50     39.10  \n",
       "1      1.74      1.74      1.80      1.78      1.75      1.69  \n",
       "2  74916.48  72571.58  66348.97  71063.72  67404.27  74920.24  \n",
       "3  44546.80  45410.53  47139.44  43095.68  40888.34  39615.19  \n",
       "4      5.94      5.73      5.22      5.30      5.73      5.91  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=5000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=5000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06583596])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.79434662e+00, -1.54437146e+00, -9.40974255e-01,\n",
       "        -1.05482128e+00, -1.26840670e+00, -6.08147386e-01,\n",
       "        -8.06337087e-01, -3.80845706e-01,  2.82854016e-01,\n",
       "         8.28701151e-01,  8.50972094e-01,  1.72739155e-01,\n",
       "         6.33553387e-01, -1.39052333e-01,  8.17391621e-01,\n",
       "         3.36478589e-01,  3.40905524e-01,  3.93426863e-01,\n",
       "         4.26256399e-01, -1.84001054e-01,  2.16448882e-01,\n",
       "         6.10621147e-01,  5.69924427e-01, -4.70168444e-02,\n",
       "         7.35347080e-02, -1.92523165e-01,  1.47589068e-01,\n",
       "         4.33825899e-01,  3.27311318e-01,  1.85592281e-01,\n",
       "         1.14968397e-01,  3.72027314e-01, -3.03311314e-01,\n",
       "        -5.35534703e-02,  7.24238223e-01,  1.23613357e-03,\n",
       "         4.69109274e-01,  5.04491135e-01, -1.96407467e-01,\n",
       "         4.07258672e-01,  1.84147987e-01,  3.12758008e-01,\n",
       "        -8.83362118e-02,  7.70836756e-01,  5.39407310e-01,\n",
       "        -8.89549241e-02,  9.48102298e-02, -1.77131902e-01,\n",
       "         1.48988513e-03, -1.02479776e-01,  1.66461954e-02,\n",
       "         3.30044538e-01,  3.46049605e-01, -1.82354714e-01,\n",
       "         9.06625029e-01, -1.74127237e-01,  6.43457350e-01,\n",
       "        -8.49744486e-02,  1.84706972e-01, -2.22816782e-01,\n",
       "         6.23642093e-01, -1.74064678e-02,  2.18236347e-01,\n",
       "         1.24157958e-01, -3.97143993e-01,  3.38559697e-01,\n",
       "        -2.32630914e-02,  4.14290381e-01,  1.21703016e-01,\n",
       "         3.21662179e-01, -1.88203034e-01, -6.46415458e-02,\n",
       "         7.05285481e-01,  6.79479754e-01, -5.86201737e-02,\n",
       "         5.19682442e-02,  2.71061474e-01, -4.08842100e-02,\n",
       "         3.53020586e-01, -5.65457810e-02,  2.66067736e-01,\n",
       "        -7.99715461e-03,  6.76544125e-01,  1.79358974e-01,\n",
       "         6.57766760e-01,  6.15091059e-01,  1.29108508e-01,\n",
       "         4.83766075e-01,  9.80432122e-01,  3.70671163e-01,\n",
       "        -1.36753476e-02, -2.32864729e-01, -7.91142295e-01,\n",
       "        -8.03124483e-01, -7.68888784e-01, -1.72726642e+00,\n",
       "        -1.41484251e+00, -1.66445102e+00, -2.11687294e+00,\n",
       "        -2.12988045e+00]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[118,   5],\n",
       "       [  8, 112]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9465020576131687"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       123\n",
      "           1       0.96      0.93      0.95       120\n",
      "\n",
      "    accuracy                           0.95       243\n",
      "   macro avg       0.95      0.95      0.95       243\n",
      "weighted avg       0.95      0.95      0.95       243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
